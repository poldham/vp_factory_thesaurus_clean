# Thesaurus Cleaning System

The project is intended to work with thesaurus files generated by [VantagePoint from Search Technology Inc](https://www.thevantagepoint.com/). The specific use case is a thesaurus containing many thousands of grouped organisation names (patent applicant names from PATSTAT). VantagePoint can create a thesaurus using a variety of metrics in a few minutes. However, further human review is often needed to ensure  accuracy. Accuracy is particularly important in cases such as patent applicant names and could involve many hours or days of careful manual review by a human. This project aims to reduce the time needed for human review.

This project aims to leverage the use of LLMs as part of VantagePoint workflows by conscripting an LLM to engage in a structured audit of a VantagePoint `.the` file involving 18,000 grouped patent applicant names. 

The project uses a local [Ollama](https://ollama.com/) hosted LLM to identify and remove false positives in thesaurus groupings as described below. It produces an audited `.the` file with false positives removed. The audited `.the` file can then be used in VantagePoint as usual.

With this approach no data leaves your machine. Processing of 18,000 groups takes a few hours on a 10 core M1 Mac Book Pro with 64Gb of RAM. That is hours that a human can spend doing something else. 

A sample `.the` file is provided for testing. 

This project represents proof of concept for extending VantagePoint capabilities using LLMs. It is a work in progress and the logic set out in agents.md can clearly be improved.  The project was created using Droid from Factory AI and can be readily used in Droid, Cursor, Claude Code or a similar AI client. Use of these clients removes the need for detailed programming knowledge. If using an AI client ask the model to read agents.md first. When using an AI client we also recommend reinforcing the needs to use .venv for requirements in the initial prompt (such as 'read agents.md and use .venv for requirements'). Setup instructions are below.


## Setup

1. **Virtual Environment**:
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   ```

2. **Ollama**:
   Ensure you have [Ollama](https://ollama.ai/) installed and running locally. With 64GB RAM, it is recommended to use one of the following:
   - **Llama 3.1 (8B)**: Fast and reliable.
     ```bash
     ollama pull llama3.1
     ```
   - **Llama 3.3 (70B)**: Most accurate, fits in 64GB RAM (using 4-bit quantization).
     ```bash
     ollama pull llama3.3
     ```
   - **Mistral Small (24B)**: Good balance of speed and entity precision.
     ```bash
     ollama pull mistral-small
     ```

If you have less than 64Gb RAM use a smaller model. A good approach is to ask an AI client to suggest a model that will fit inside your RAM that is good for the task. You can ask the AI client to suggest a model from the list of Ollama models here: https://ollama.com/search


## Usage

Run the cleaning script and optionally specify the model:

```bash
python clean_thesaurus.py factory_working_example_group_normalized_30122025.the --model llama3.3
```

## How it Works

The script parses the `.the` file (UTF-16 encoded) and groups aliases under their headers. It then sends each group to the LLM (via Ollama) to identify outliers based on the logic defined in `agents.md`.

### Core Logic & Enhancements
- **Algorithmic Pre-filtering**: Uses Jaccard-like string similarity and generic word detection to flag suspicious entries before the LLM review.
- **One-Word Variance**: Explicitly rejects aliases that share only a single generic word (e.g., "Shanghai Pharma" vs "Pharma Global").
- **Chain-of-Thought Auditing**: Instructs the model to perform step-by-step mental verification for better entity resolution.
- **Distinctive Names**: Keep names sharing a distinctive root.
- **Generic Names**: Remove names that only share a generic term (e.g., "Pharma").
- **Specific Entities**: Distinguish between similar entities like NYU and SUNY.

